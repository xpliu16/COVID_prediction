packageDescription('bnlearn')
data(coronary)
library(bnlearn)
data(coronary)
bn_df<-data.frame(coronary)
res<-hc(bn_df)
plot(res)
res$arcs <- res$arcs[-which((res$arcs[,'from'] == "M..Work" & res$arcs[,'to'] == "Family"))]
help("which")
fittedbn <- bn.fit(res,data = bn_df)
bn_df<-data.frame(coronary)
res <-hc(bn_df)
res$arcs<-res$arcs[-which((res$arcs[,'from']=="M..Work" & res$arcs[,'to'] = "Family")),]
res$arcs<-res$arcs[-which((res$arcs[,'from']=="M..Work" & res$arcs[,'to'] == "Family")),]
fittedbn <- bn.fit(res,data=bn_df)
print(fittedbn$Proteins)
cpquery(fittedbn,event = (Proteins=="
cpquery(fittedbn,event = (Proteins=="yes")
)
cpquery(fittedbn,event = (Proteins=="140")
cpquery(fittedbn,event = (Proteins=="140"))
cpquery(fittedbn,event = (Proteins=="140"))
print(fittedbn$Proteins)
cpquery(fittedbn, event = (Proteins==1))
cpquery(fittedbn, event = (Proteins==TRUE))
cpquery(fittedbn, event = (Proteins=="<3"))
cpquery(fittedbn,(Proteins=="<3"),(Smoking=="no"))
cpquery(fittedbn,event = (Proteins=="<3"),evidence =(Smoking=="no",pressure=="140"))
cpquery(fittedbn,Proteins=="<3",list(Smoking=="no",Pressure=="140"))
cpquery(fittedbn,Proteins=="<3",list(Smoking=="no",Pressure==">140"))
print(fittedbn$Pressure)
cpquery(fittedbn,Proteins=="<3",list(Pressure==">140"))
cpquery(fittedbn,Proteins=="<3",Pressure==">140")
cpquery(fittedbn,Proteins=="<3",list(Smoking="no",Pressure=">140"))
cpquery(fittedbn,Proteins=="<3",list(Smoking=="no",Pressure==">140"))
cpquery(fittedbn,Proteins=="<3",(Smoking=="no")&(Pressure==">140"))
cpquery(fittedbn,Pressure==">140",Proteins==">3")
data(learning.test)
bn <- hc(learning.test)
plot(bn)
fitted<-bn.fit(bn, learning.test)
ev <- learning.test[2,-4]
learning.test
ev
cpquery(fitted,list(D="b"),ev)
cpquery(fitted,list(D=="b"),ev)
install.packages("Rtsne")
train<- read.csv("C:\Users\Ping\Documents\MATLAB\Xblaster3_Chamber3_GIT\XPL_code\Paper_code_and_spreadsheets\CSV\X_classify.csv") ## Choose the train.csv file downloaded from the link above
library(Rtsne)
## Curating the database for analysis with both t-SNE and PCA
Labels<-train$label
train$label<-as.factor(train$label)
## for plotting
colors = rainbow(length(unique(train$label)))
names(colors) = unique(train$label)
## Executing the algorithm on curated data
tsne <- Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
exeTimeTsne<- system.time(Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500))
## Plotting
plot(tsne$Y, t='n', main="tsne")
text(tsne$Y, labels=train$label, col=colors[train$label])
train
train<- read.csv("C:\Users\Ping\Documents\MATLAB\Xblaster3_Chamber3_GIT\XPL_code\Paper_code_and_spreadsheets\CSV\X_classify.csv")
train<- read.csv(r"C:\Users\Ping\Documents\MATLAB\Xblaster3_Chamber3_GIT\XPL_code\Paper_code_and_spreadsheets\CSV\X_classify.csv")
train<- read.csv("C:/Users/Ping/Documents/MATLAB/Xblaster3_Chamber3_GIT/XPL_code/Paper_code_and_spreadsheets/CSV/X_classify.csv")
## Curating the database for analysis with both t-SNE and PCA
Labels<-train$label
train$label<-as.factor(train$label)
## for plotting
colors = rainbow(length(unique(train$label)))
names(colors) = unique(train$label)
tsne <- Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
exeTimeTsne<- system.time(Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500))
train <- na.omit(train)
tsne <- Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
exeTimeTsne<- system.time(Rtsne(train[,-1], dims = 2, perplexity=30, verbose=TRUE, max_iter = 500))
plot(tsne$Y, t='n', main="tsne")
text(tsne$Y, labels=train$label, col=colors[train$label])
tsne$Y
plot(tsne$Y)
tsne <- Rtsne(train[,-1], dims = 2, perplexity=20, verbose=TRUE, max_iter = 1000)
plot(tsne$Y)
tsne <- Rtsne(train[,-1], dims = 2, perplexity=35, verbose=TRUE, max_iter = 1000)
plot(tsne$Y)
tsne <- Rtsne(train[,-1], dims = 2, perplexity=45, verbose=TRUE, max_iter = 1000)
plot(tsne$Y)
train[1:10,]
tsne <- Rtsne(train[,], dims = 2, perplexity=45, verbose=TRUE, max_iter = 1000)
plot(tsne$Y)
tsne <- Rtsne(train[,], dims = 2, perplexity=35, verbose=TRUE, max_iter = 1000)
plot(tsne$Y)
# Second phase as mask wearing and social distancing begin to be encouraged
df_post2_CA = filter(df_gt,date>as.Date("2020-05-20")& state=="US-CA")
df_post2_CA = subset(df_post2_CA, select = -c(state))
library(dplyr)
library(ggplot2)
library(scales)
library(tidyr)
library(reshape2)
library(forecast)
library(imputeTS)
library(FBN)
library(covidcast)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
deseason <- function(df,plotornot) {
hits_no_na <- na_ma(df$hits, weighting = "simple")
med_filt <- medianFilter(hits_no_na, 3)
trend_ma = ma(as.ts(med_filt), order = 52, centre = T)
detrend = med_filt / trend_ma
m_seas = t(matrix(data = detrend[27:(27+2*52-1)], nrow = 52))
seas_mean = colMeans(m_seas, na.rm = T)
temp = rep(seas_mean,8)
temp2 = ma(as.ts(temp), order = 4,centre = T)
seas_rep = temp2[(52-27+1+1):((52-27+1+1)+length(df$hits)-1)]
deseas = med_filt / seas_rep
if (plotornot) {
plot(as.ts(df$hits))
lines(trend_ma)
plot(as.ts(seas_rep))
}
return(deseas)
# Also consider decompose() and stl()
}
normalize <- function(x) {
return ((x - min(x,na.rm=T)) / (max(x,na.rm=T) - min(x,na.rm=T)))
}
df_gt = read.csv("data\\gtrend_data.csv")
df_gt$date <- as.Date(df_gt$date)
df_gt$hits<-as.numeric(df_gt$hits)
search_terms <- c("curbside","outdoor dining",
"library hours","bar","best masks",
"indoor playground","evite","flight")
states = c("US-CA","US-TX","US-FL","US-NY","US-PA")
df_pre = filter(df_gt,date<as.Date("2020-02-01"))
df_post = filter(df_gt,date>as.Date("2020-03-20"))
# Second phase as mask wearing and social distancing begin to be encouraged
#df_post2 = filter(df_gt,date>as.Date("2020-05-20"))
print(paste("Length total:", dim(df_gt)[1]))
print(paste("Length pre-COVID:", dim(df_pre)[1]))
print(paste("Length post-COVID:", dim(df_post)[1]))
ggplot(filter(df_gt,state=="US-CA"), aes(x=date, y=hits)) +
geom_line() +
xlab("Date")+
facet_grid(search_term~.,
labeller = label_wrap_gen(width = 2, multi_line = TRUE))
# Try for CA
df_post_CA = filter(df_post,state == "US-CA")
bar_CA = filter(df_post,state == "US-CA" & search_term == "bar")
curbside_CA = filter(df_post,state == "US-CA" & search_term == "curbside")
for (words in search_terms) {
df_post_CA$hits[df_post_CA$search_term==words]<-
df_post_CA$hits[df_post_CA$search_term==words]/
max(df_post_CA$hits[df_post_CA$search_term==words])*
100
}
for (words in c("library hours","bar","indoor playground","evite","flight")) {
# Terms showing decrease in caution
df_post_CA$hits[df_post_CA$search_term==words]<-
-1*df_post_CA$hits[df_post_CA$search_term==words]
}
ggplot(df_post_CA, aes(x=date, y=hits, colour=search_term, group=search_term)) +
geom_point(size=1) +
geom_line(size=1) +
scale_y_continuous(limits = c(-100,100), breaks=seq(-100,100,25)) +
ylab("Normalized hits") +
scale_x_date(date_breaks = "3 months" , date_labels = "%b-%y")
# Second phase as mask wearing and social distancing begin to be encouraged
df_post2_CA = filter(df_gt,date>as.Date("2020-05-20")& state=="US-CA")
df_post2_CA = subset(df_post2_CA, select = -c(state))
df_post2_CA_wide <- spread(df_post2_CA, search_term, hits)
df_post2_CA_wide = subset(df_post2_CA_wide, select = -c(date))
cormat <-cor(df_post2_CA_wide)
cormat <- reorder_cormat(cormat)
melted_cormat <- melt(cormat)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "cyan3", high = "coral", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "darkcyan", high = "coral", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "aquamarine3", high = "coral", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "darkturquoise", high = "coral", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "darkslategray", high = "coral", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation")+
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
df <- data.frame(df_sub$date, df_sub$caution)
df <- data.frame(data_sub$date, data_sub$caution)
df_gt = read.csv("data\\gtrend_data.csv")
df_gt$date <- as.Date(df_gt$date)
df_gt$hits<-as.numeric(df_gt$hits)
search_terms <- c("curbside","outdoor dining",
"library hours","bar","best masks",
"indoor playground","evite","flight")
states = c("US-CA","US-TX","US-FL","US-NY","US-PA")
df_pre = filter(df_gt,date<as.Date("2020-02-01"))
df_post = filter(df_gt,date>as.Date("2020-03-20"))
s <- "US-PA"
words <- "bar"
s <- "US-NY"
words <- "outdoor dining"
df_sub = subset(df_gt, state==s & search_term==words)
deseas = deseason(df_sub,1)
par(mfrow=c(2,2),
oma = c(1,1,1,1),
mar = c(3,2,3,1.5))
plot(df_sub$date,df_sub$hits,type ="l",
xlim=c(as.Date("2017-11-18"),as.Date("2020-02-01")),
main="Baseline original\n\"outdoor dining\"",
font.main=1,
ylim=c(0,45),
xlab="",
ylab="")
deseas_all = NULL
test_state = "US-CA"
states = c(test_state)
for (s in states){
for (i in 1:length(search_terms)){
df_sub = subset(df_gt, state==s & search_term==search_terms[i])
deseas_all = append(deseas_all,deseason(df_sub,0))
}
deseas_mat <- matrix(deseas_all, ncol=length(search_terms),byrow=FALSE)
deseas_scaled <- scale(deseas_mat, center = TRUE, scale = TRUE)
terms.pca <- prcomp(deseas_scaled, center = FALSE, scale. = FALSE) # PCA
summary(terms.pca)
}
caution = deseas_scaled %*% terms.pca$rotation[,1]
plot(df_sub$date,caution,type="l")
df_sub$caution_norm<-normalize(caution)
df <- data.frame(df_sub$date, df_sub$caution)
write.csv(df,"C:\\Users\\Ping\\Desktop\\Project\\COVID_prediction\\data\\gtrend_data.csv", row.names = FALSE)
write.csv(df,"C:\\Users\\Ping\\Desktop\\Project\\COVID_prediction\\data\\gtrend_caution.csv", row.names = FALSE)
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
df <- data.frame(df_sub$date, df_sub$caution)
colnames(df) <- c("date","caution")
write.csv(df,"C:\\Users\\Ping\\Desktop\\Project\\COVID_prediction\\data\\gtrend_caution.csv", row.names = FALSE)
help(normalize)
help("normalize")
#states <- paste0("US-",state.abb)
#states <- states[-2]
states = c("US-CA","US-TX","US-FL","US-NY","US-PA","US-SD")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
install.packages("vars")
library(vars)
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
#states <- paste0("US-",state.abb)
#states <- states[-2]
#states = c("US-CA","US-TX","US-FL","US-NY","US-PA","US-SD")
states = c("US-SD")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_predict_explor.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_predict_explor.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_predict_explor.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_get_data.R")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_predict_explor.R")
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
head(df_cv)
install.packages("zoo")
install.packages("zoo")
install.packages("xts")
source("C:/Users/Ping/Desktop/Project/COVID_prediction/COVID_predict_explor.R")
df_cv <- as.xts(df_cv$value,order.by=as.Date(df_cv$index))
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
df_cv2 <- as.xts(df_cv$new_case,order.by=as.Date(df_cv$submission_date))
df_cv$submission_date)
df_cv$submission_date
as.Date(df_cv$submission_date)
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
df_ca = df_cv[df_cv.state=="US-CA"]
head(df_cv)
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
df_ca = df_cv[df_cv.state=="US-CA"]
df_cv.state
df_ca = df_cv[df_cv$state=="US-CA"]
df_cv2 <- as.xts(df_ca$new_case,order.by=as.Date(df_ca$submission_date))
as.Date(df_ca$submission_date)
head(df_ca)
df_ca = df_cv[df_cv$state=="CA"]
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
df_ca = df_cv[df_cv$state=="CA"]
df_cv$state
df_ca = subset(df_cv, state=="CA")
df_cv2 <- as.xts(df_ca$new_case,order.by=as.Date(df_ca$submission_date))
df_ca$submission_date
summary(df_ca)
info(df_ca)
sapply(df_ca$submission_date, is.null)
# Grab new cases
df_cv = read.csv("data\\United_States_COVID-19_Cases_and_Deaths_by_State_over_Time.csv")
df_ca = subset(df_cv, state=="CA")
df_cv2 <- as.xts(df_ca$new_case,order.by=as.Date(df_ca$submission_date))
sapply(asDate(df_ca$submission_date), is.null)
sapply(as.Date(df_ca$submission_date), is.null)
sapply(as.Date(df_ca$submission_date), is.infinite)
df_cv2 <- as.xts(df_ca$new_case,order.by=as.Date(df_ca$submission_date))
install.packages("lubridate")
df_ca$week <- floor_date(as.date(df_ca$submission_date), "week")
library(lubridate)
df_ca$week <- floor_date(as.date(df_ca$submission_date), "week")
df_ca$week <- floor_date(as.Date(df_ca$submission_date), "week")
df_ca %>%
group_by(week) %>%
summarize(mean = mean(new_case))
df_ca$week
as.Date(df_ca$submission_date)
df_ca$submission_date
help(as.Date)
detach(package:xts, unload = TRUE)
detach(package:zoo, unload = TRUE)
